name: üï∑Ô∏è Node Crawler & Filter (Auto Update)

on:
  schedule:
    - cron: '0 */6 * * *'  # ÊØè6Â∞èÊó∂Ëá™Âä®ËøêË°å‰∏ÄÊ¨°
  workflow_dispatch:  # ÊîØÊåÅÊâãÂä®Ëß¶Âèë

jobs:
  run-crawler:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Ê£ÄÂá∫‰ªìÂ∫ì
      - name: Checkout repository
        uses: actions/checkout@v4

      # Step 2: ËÆæÁΩÆ Python ÁéØÂ¢É
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      # Step 3: ÂÆâË£Ö‰æùËµñ
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip

      # Step 4: ËøêË°åÁà¨Ëô´ËÑöÊú¨
      - name: Run crawler and filter nodes
        run: |
          cd .github/workflows
          python filter_crawler.py

      # Step 5: Â∞ÜÁªìÊûúÊñá‰ª∂ËΩ¨‰∏∫ Base64
      - name: Encode output and save as config.txt
        run: |
          cd .github/workflows
          base64 -w 0 filtered_nodes.txt > ../../config.txt

      # Step 6: Êèê‰∫§Êõ¥Êñ∞
      - name: Commit and push changes
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add ../../config.txt .github/workflows/filtered_nodes.txt || true
          git commit -m "ü§ñ Auto-update filtered_nodes.txt & config.txt" || echo "No changes to commit"
          git push origin main || echo "No changes to push"
        continue-on-error: true
